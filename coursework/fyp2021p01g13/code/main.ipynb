{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-406de892-9df3-40b3-b971-268594971f28",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h2 style=\"color:#22198A\">PROJECT INFO</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">About project-01</h3>\n",
    "<p>This project is focused analysing data from UK government concerning accidents in the UK in year 2019. Our group specifically analysed <b>Manchester.</b></p>\n",
    "<p><b>Contact:</b> luci@itu.dk, mdon@itu.dk, jses@itu.dk, mksi@itu.dk</p>\n",
    "<p><b>Created:</b> 08. 02. 2021</p>\n",
    "<p><b>Last modified:</b> 25. 02. 2021</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-21909987-4a60-450a-9dd4-21c082bd9b34",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h2 style=\"color:#22198A\">NOTEBOOK SETUP</h2>\n",
    "<p>Before you start working with notebook, please make sure to go through this setup to ensure smooth running. (by default, no changes should be needed if you just downloaded the repository)</p>\n",
    "<h3 style=\"color:green\">Important highlights</h3>\n",
    "<ul>\n",
    "<li><b>BASE_DIR:</b> This should lead to the root directory relative to location of this notebook</li>\n",
    "<li><b>SCRIPTS IMPORT:</b> All scripts are saved within one file. In the file, there are comments splitting the whole file into sections which gather scripts with similar functionality, e.g. loading data. All functions should contain docstring, which might be useful for any troubleshooting or just knowing how the given thing was implemented. The way the scripts are imported was implemented according to <a href='# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "'>this</a> SO question. <b>Once you run the below cell, all scripts should be loaded.</b></li>\n",
    "<li><b>PACKAGES USED WITHIN DIRECTORY: </b> Most of the functionality is written in <b>all_scripts.py</b> where you can see in the beginning all the packages used, but it is worth highlight these \"not so standard\" packages which you should make sure you have installed: <b>pandas, scipy, branca, geopy, sklearn, openpyxl</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-fc4cc5f8-b87e-4a27-8ecc-ce98e849c891",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"\"\n",
    "\n",
    "# SCRIPTS IMPORT\n",
    "import os\n",
    "import sys\n",
    "scripts_path = os.path.abspath(os.path.join(f'{BASE_DIR}scripts'))\n",
    "\n",
    "if scripts_path not in sys.path:\n",
    "    # Add the scripts to the path\n",
    "    sys.path.append(scripts_path)\n",
    "    \n",
    "    # Import the needed scripts\n",
    "    from all_scripts import *\n",
    "    \n",
    "    # Remove the added path to avoid possible future conflicts\n",
    "    sys.path.remove(scripts_path)\n",
    "else:\n",
    "    \n",
    "    # Import the needed scripts\n",
    "    from all_scripts import *\n",
    "    \n",
    "    # Remove the added path to avoid possible future conflicts\n",
    "    sys.path.remove(scripts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-d665c462-5b58-4089-bfbf-f492bb85fbd7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h2 style=\"color:#22198A\">CONSTANTS</h2>\n",
    "<h3 style=\"color:green\">Important highlights</h3>\n",
    "<ul>\n",
    "<li><b>PATH_REFERENCES:</b> There was an original variable lookup table  which we modified, so var lookup leads to this modified table. The reason for this step was being able to use column names from individual datasets to index Sheet names in the variable lookup file. The problem was that certain sheet names had unfortunately different names than column names. For more detail, look at script <b>map_num_cat_to_named_cat</b></li>\n",
    "<li><b>NAMING CONVENTIONS - TABLES:</b> Since there are three datasets, we usually store these throughout the notebook using a dictionary. The important thing to notice, that the dictionary always has the following keys referencing to tables: <b>accidents, casualties, vehicles</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-0b9f4cd4-056f-4102-9777-dfa08647c3b4",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "PATH_DATA = {\n",
    "    \"raw\": f\"{BASE_DIR}data/raw/\",\n",
    "    \"interim\": f\"{BASE_DIR}data/interim/\",\n",
    "    \"external\": f\"{BASE_DIR}data/external/\"\n",
    "    \n",
    "}\n",
    "\n",
    "PATH_REFERENCES = {\n",
    "    \"var_lookup\": f\"{BASE_DIR}references/variable_lookup_modified.xlsx\"\n",
    "}\n",
    "\n",
    "FILENAME_DATA = {\n",
    "    \"accidents\": \"Road Safety Data - Accidents 2019.csv\",\n",
    "    \"casualties\": \"Road Safety Data - Casualties 2019.csv\",\n",
    "    \"vehicles\": \"Road Safety Data- Vehicles 2019.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-c83eb0de-419a-40e3-bac4-72647edd4b96",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h2 style=\"color:#22198A\">LOAD RAW DATA</h2>\n",
    "<h3 style=\"color:green\">Important highlights</h3>\n",
    "<ul>\n",
    "<li><b>LOADING RAW DATA:</b> We loaded the data as a masked numpy array. The only difference compare to lecture is that we also used parameter <b>missing_values</b> and set it to {'-1', ''} which specifies explicitly how are defined missing values. We made the decision after exploring variable lookup dataset.</li>\n",
    "<li><b>LOADING VAR LOOKUP</b> Since we modified the file, the format of excel sheet is not xls anymore, but xlsx (more modern version of storing excel data <a href='https://stackoverflow.com/questions/65250207/pandas-cannot-open-an-excel-xlsx-file'>since 2007</a>), you might need to install <b>openpyxl</b>, if you are using Anacando, then read how <a href=https://anaconda.org/anaconda/openpyxl>here</a>. For troubleshooting, see this <a href=https://stackoverflow.com/questions/65250207/pandas-cannot-open-an-excel-xlsx-file>SO answer.</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-7f1b2a21-cf8b-4e5d-bec9-d99aa0d1c625",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "RAW_DATA = {\n",
    "    key: load_data_numpy_csv(PATH_DATA['raw'] + filename)\n",
    "    for key, filename in FILENAME_DATA.items()\n",
    "}\n",
    "\n",
    "VAR_LOOKUP = load_pandas_df_from_excel(PATH_REFERENCES['var_lookup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name, records in RAW_DATA.items():\n",
    "    print(f'There is in total {records.shape[0]} records in {table_name} table.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-3499d7ef-6c10-42ff-bfcb-1f8bbc178962",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h2 style=\"color:#22198A\">TASK 0: DATA FILTERING, CLEANING AND EXPLORING</h2>\n",
    "<h3 style=\"color:green\">Get only accidents related to Manchester</h3>\n",
    "<br>\n",
    "<p> We decided to use Local Authority District code to filter out the relvant results for Manchester. See the process below.</p>\n",
    "<p><b>NOTE:</b> We only considered Manchester as a city and not the whole Greater Manchester area. The reason is that Manchester as a city has its own local government and even more importantly we were tasked to analyse Manchester as a city.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">EXPLORE POSIBILITIES FOR SELECTING MANCHESTER CITY DATA.</h4>\n",
    "<p>After the exploration of variables within accident table we found two variables which should be relevant: <b>Local_Authority_Highway and Local_Authority_District</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check validity of the values\n",
    "missing_vals_highway = np.count_nonzero(RAW_DATA['accidents']['Local_Authority_Highway'].mask)\n",
    "missing_vals_district = np.count_nonzero(RAW_DATA['accidents']['Local_Authority_District'].mask)\n",
    "print(f\"Local authority district has {missing_vals_district} missing values and Local Authority Highway has {missing_vals_highway} missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This seems to be a good idea. In fact there is a wikipedia webpage showing that Local authority district is something which we should look for since there are different districts within the Greater Manchester city area and Manchester city is one of them with its own local council. <a href=\"https://en.wikipedia.org/wiki/Category:Local_authorities_in_Greater_Manchester\">See it here.</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the Manchester records based on the two variables and see if they match\n",
    "manchester_only_mask_highway = RAW_DATA['accidents']['Local_Authority_Highway'] == 'E08000003'\n",
    "manchester_only_highway = RAW_DATA['accidents'][manchester_only_mask_highway]\n",
    "\n",
    "manchester_only_mask_district = RAW_DATA['accidents']['Local_Authority_District'] == 102\n",
    "manchester_only_district = RAW_DATA['accidents'][manchester_only_mask_district]\n",
    "print(f\"Using the Highway code, we obtained {manchester_only_highway.shape[0]} records and the district code we obtained {manchester_only_district.shape[0]} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">SELECT THE DATA FOR MANCHESTER</h4>\n",
    "<p>Now, that we know the two variables yielded the same result, we decided to choose Local Authority District as the one to rely on during the rest of the analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accidents relevant to Manchester\n",
    "ACCIDENTS_IN_MANCHESTER = get_city_specific_records_by_lad(RAW_DATA['accidents'], 102)\n",
    "print(f'There is {ACCIDENTS_IN_MANCHESTER.shape[0]} accident records related to MANCHESTER.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-c9980912-8425-41d5-a646-cb459b1932b0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h3 style=\"color:green\">Use accident indexes related to Manchester to select relevant data from other two tables</h3>\n",
    "<h4 style=\"color:#ff9900\">SANITY CHECK: DOES EVERY ACCIDENT ID IN THE CASUALTIES AND VEHICLES TABLE HAVE THEIR CORESSPONDING ACCIDENT ID IN THE ACCIDENT TABLE?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-55bf5c83-0414-44cd-85bf-fe8b9070b57e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "for other_table in RAW_DATA.keys():\n",
    "    if other_table != 'accidents':\n",
    "        print(f'Table: {other_table.upper()}')\n",
    "        non_existent_ids = is_accident_id_existent(RAW_DATA['accidents'], RAW_DATA[other_table])\n",
    "        if not non_existent_ids:\n",
    "            print(f'- OK: All Accident IDs in {other_table} have corresponding ID in accident table.')\n",
    "        else:\n",
    "            print(non_existent_ids)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-b9fb7bcc-8783-43e0-9bba-3d0324a1fabb",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h4 style=\"color:#ff9900\">SELECT RELEVANT RECORDS FOR MANCHESTER FROM OTHER TWO TABLES</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-ba6f33cf-96a1-43b4-9681-0a6d8cb94ce9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Mask\n",
    "mask_casualties = np.isin(RAW_DATA['casualties']['Accident_Index'], ACCIDENTS_IN_MANCHESTER['Accident_Index'])\n",
    "mask_vehicles = np.isin(RAW_DATA['vehicles']['Accident_Index'], ACCIDENTS_IN_MANCHESTER['Accident_Index'])\n",
    "\n",
    "# Select the corresponding records\n",
    "CASUALTIES_IN_MANCHESTER = RAW_DATA['casualties'][mask_casualties]\n",
    "VEHICLES_IN_MANCHESTER = RAW_DATA['vehicles'][mask_vehicles]\n",
    "\n",
    "print(f'There are {CASUALTIES_IN_MANCHESTER.shape[0]} casuality records and {VEHICLES_IN_MANCHESTER.shape[0]} vehicles records.', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-bcc89294-2e75-4d92-85f8-952e3b1f674e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h3 style=\"color:green\">Select only relevant columns from all tables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-d330fc6b-9018-4e68-b5fe-ae0b71d10467",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# TODO: Add description why we chose given columns\n",
    "MANCHESTER_ONLY_RECORDS = {\n",
    "    'accidents': ACCIDENTS_IN_MANCHESTER,\n",
    "    'casualties': CASUALTIES_IN_MANCHESTER,\n",
    "    'vehicles': VEHICLES_IN_MANCHESTER\n",
    "}\n",
    "\n",
    "\n",
    "SELECTED_COLUMNS = {\n",
    "    'accidents': [\n",
    "        'Accident_Index',\n",
    "        'Longitude',\n",
    "        'Latitude',\n",
    "        'Accident_Severity',\n",
    "        'Number_of_Vehicles',\n",
    "        'Number_of_Casualties',\n",
    "        'Date',\n",
    "        'Day_of_Week',\n",
    "        'Road_Type',\n",
    "        'Time',\n",
    "        'Speed_limit',\n",
    "        'Junction_Detail',\n",
    "        'Junction_Control',\n",
    "        'Pedestrian_CrossingHuman_Control',\n",
    "        'Light_Conditions',\n",
    "        'Weather_Conditions',\n",
    "        'Road_Surface_Conditions',\n",
    "        'Special_Conditions_at_Site',\n",
    "        'Carriageway_Hazards'\n",
    "    ],\n",
    "    'casualties': [\n",
    "        'Accident_Index',\n",
    "        'Casualty_Class',\n",
    "        'Sex_of_Casualty',\n",
    "        'Age_of_Casualty',\n",
    "        'Age_Band_of_Casualty',\n",
    "        'Pedestrian_Location',\n",
    "        'Pedestrian_Movement',\n",
    "        'Car_Passenger',\n",
    "        'Casualty_Severity',\n",
    "        'Bus_or_Coach_Passenger',\n",
    "        'Casualty_Type'\n",
    "    ],\n",
    "    'vehicles': [\n",
    "        'Accident_Index',\n",
    "        'Towing_and_Articulation',\n",
    "        'Vehicle_Manoeuvre',\n",
    "        'Vehicle_LocationRestricted_Lane',\n",
    "        'Junction_Location',\n",
    "        'Skidding_and_Overturning',\n",
    "        'Hit_Object_in_Carriageway',\n",
    "        'Vehicle_Leaving_Carriageway',\n",
    "        'Hit_Object_off_Carriageway',\n",
    "        '1st_Point_of_Impact',\n",
    "        'Sex_of_Driver',\n",
    "        'Age_of_Driver',\n",
    "        'Age_Band_of_Driver',\n",
    "        'Age_of_Vehicle'\n",
    "    ]\n",
    "}\n",
    "\n",
    "SELECTED_DATA = {\n",
    "    key: select_only_relevant_columns(MANCHESTER_ONLY_RECORDS[key], sel_columns)\n",
    "    for key, sel_columns in SELECTED_COLUMNS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-ebf291ec-1cf3-4b7d-9d45-00db2d944db3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h3 style=\"color:green\">Do a summary of the adjusted tables</h3>\n",
    "<h4 style=\"color:#ff9900\">INFORMATION ABOUT THE FILTERED DATASETS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00026-b534edf0-258e-47a2-9d3a-27072b460dc1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "datasets_info =  get_info_datasets(SELECTED_DATA)\n",
    "for key, info in datasets_info.items():\n",
    "    print(f'{key}'.upper())\n",
    "    for info_key, value in info.items():\n",
    "        if info_key != \"column names\":\n",
    "            print(info_key, ': ', value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00027-6bf9ee06-fe2e-4103-9a67-271938b69d2e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h4 style=\"color:#ff9900\"> NUMERICAL DATA: FIVE NUMBER SUMMARY</h4>\n",
    "<p>Select below, whether you want to see 5 number summary graphically (boxplots) or not.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_BOXPLOTS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Define columns with numerical data for each table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DATA = {\n",
    "    'accidents': ['Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit'],\n",
    "    'vehicles': ['Age_of_Driver', 'Age_of_Vehicle'],\n",
    "    'casualties': ['Age_of_Casualty']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are no missing values in selected columns\n",
    "for table, column_names in NUMERICAL_DATA.items():\n",
    "    print(f\"In the table {table}\")\n",
    "    for column_name in column_names:\n",
    "        print(f\"  there is in total {np.count_nonzero(SELECTED_DATA[table][column_name].mask)} missing values in the column {column_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00030-6e90e711-b3c8-4caf-b2bb-2765c3b8910f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Visual 5 number summary\n",
    "if PLOT_BOXPLOTS:\n",
    "    for table_name, num_col_names in NUMERICAL_DATA.items():\n",
    "        boxplots(SELECTED_DATA[table_name], num_col_names, n_rows=1)\n",
    "\n",
    "# 5 number summary for numerical data\n",
    "else:\n",
    "    print('==========================================')\n",
    "    print()\n",
    "    for table_name, num_col_names in NUMERICAL_DATA.items():    \n",
    "        five_num_summary = get_5_num_sum(SELECTED_DATA[table_name], columns=num_col_names)\n",
    "        print(f'{table_name.upper()} TABLE')\n",
    "        for column_name, values in five_num_summary.items():\n",
    "            print(f'- {column_name.upper()}')\n",
    "            for key, number in values.items():\n",
    "                print(f'  {key}: {number}')\n",
    "            print()\n",
    "        print()\n",
    "        print('==========================================')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-77673718-a02b-4050-a535-7fbbc58edbac",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h4 style=\"color:#ff9900\"> CATEGORICAL DATA - ACCIDENTS TABLE</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-5c202fd5-abd9-4fc3-92e2-5c20017cfbba",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "selected_column_names_accidents = [\n",
    "    'Accident_Severity',\n",
    "    'Day_of_Week',\n",
    "    'Road_Type',\n",
    "    'Speed_limit',\n",
    "    'Junction_Detail',\n",
    "    'Junction_Control',\n",
    "    'Light_Conditions',\n",
    "    'Weather_Conditions',\n",
    "    'Road_Surface_Conditions',\n",
    "    'Special_Conditions_at_Site',\n",
    "    'Carriageway_Hazards',\n",
    "    'Pedestrian_CrossingHuman_Control'\n",
    "    ]\n",
    "freqBar(SELECTED_DATA['accidents'],\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names_accidents,\n",
    "        figheight=30,\n",
    "        figwidth=15,\n",
    "        hspace=0.8,\n",
    "        nrows=4,\n",
    "        check_missing_vals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\"> CATEGORICAL DATA - VEHICLES TABLE</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column_names_vehicles = [\n",
    "    'Towing_and_Articulation',\n",
    "    'Vehicle_Manoeuvre',\n",
    "    'Junction_Location',\n",
    "    'Skidding_and_Overturning',\n",
    "    'Hit_Object_in_Carriageway',\n",
    "    'Vehicle_Leaving_Carriageway',\n",
    "    'Hit_Object_off_Carriageway',\n",
    "    '1st_Point_of_Impact',\n",
    "    'Sex_of_Driver'\n",
    "    ]\n",
    "freqBar(SELECTED_DATA['vehicles'],\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names_vehicles,\n",
    "        figheight=35,\n",
    "        figwidth=15,\n",
    "        hspace=0.8,\n",
    "        check_missing_vals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\"> CATEGORICAL DATA - CASUALTIES TABLE</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column_names_casualties = [\n",
    "    'Casualty_Class',\n",
    "    'Sex_of_Casualty',\n",
    "    'Casualty_Severity',\n",
    "    'Pedestrian_Location',\n",
    "    'Car_Passenger',\n",
    "    'Bus_or_Coach_Passenger',\n",
    "    'Casualty_Type'\n",
    "]\n",
    "freqBar(SELECTED_DATA['casualties'],\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names_casualties,\n",
    "        figheight=35,\n",
    "        figwidth=17,\n",
    "        hspace=0.5,\n",
    "        nrows=3,\n",
    "        check_missing_vals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-9bdec2bf-d076-4f60-afd2-044600693678",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h3 style=\"color:green\">Save the adjusted tables to data/interim</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-7164d014-fee1-42a1-a1d6-a02e8c3da39a",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "for key, arr in SELECTED_DATA.items():\n",
    "    \n",
    "    # Get proper filename\n",
    "    fname = FILENAME_DATA[key]\n",
    "    \n",
    "    # Get filepath\n",
    "    filepath = f\"{PATH_DATA['interim']}{fname}\"\n",
    "    header = ','.join(arr.dtype.names)\n",
    "    np.savetxt(filepath, arr, fmt='%s', delimiter=',', header=header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-5408e098-4e8e-4de5-9f7a-e0333b065f02",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h2 style=\"color:#22198A\">Task 1: Single variable analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00037-cacb628f-4abb-48c3-aceb-92cfcb12d8d9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "CLEAN_DATA = {\n",
    "    key: load_data_numpy_csv(PATH_DATA['interim'] + filename)\n",
    "    for key, filename in FILENAME_DATA.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-84fb953e-1ccf-4267-9de3-d62c8697315d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h3 style=\"color:green\">Age of driver</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00039-e3a9a62d-b450-4d4d-9597-815451055dd9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Get valid data since we know there is 234 records missing\n",
    "no_missing_vals_mask = ~(CLEAN_DATA['vehicles']['Age_of_Driver'].mask)\n",
    "age_driver_defined_vals_only = CLEAN_DATA['vehicles']['Age_of_Driver'][no_missing_vals_mask]\n",
    "\n",
    "# Plot the graph\n",
    "histograms(CLEAN_DATA['vehicles']['Age_of_Driver'],\n",
    "           selected_column_names=['Age of Driver'],\n",
    "           figheight=5,\n",
    "           figwidth=15,\n",
    "           hspace=0.5,\n",
    "           nrows=1,\n",
    "           nbins=25,\n",
    "          xticks=[i for i in range(0, 110, 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-9efde3e5-023b-4886-a105-b08cc74c397d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<h3 style=\"color:green\">Histogram of time, day and date</h3>\n",
    "<h4 style=\"color:#ff9900\">TIME</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all time data which are in the format hh:mm\n",
    "time_data = CLEAN_DATA['accidents']['Time']\n",
    "\n",
    "# Parse hours from the data\n",
    "hours = [strip_number_from_zero(time[0]) for time in np.char.split(time_data, sep=\":\")]\n",
    "\n",
    "# Convert the list into array and use int as dtype\n",
    "hours_arr = np.array(hours).astype(int)\n",
    "\n",
    "# Plot the data\n",
    "histograms(hours_arr,\n",
    "           selected_column_names=['Accident hours'],\n",
    "           figheight=5,\n",
    "           figwidth=17,\n",
    "           hspace=0.5,\n",
    "           nrows=1,\n",
    "           nbins=12,\n",
    "           xticks=[i for i in range(0, 26, 2)],\n",
    "           range=(0, 24)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">WEEKDAY</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_data = CLEAN_DATA['accidents']['Day_of_Week']\n",
    "\n",
    "freqBar(weekday_data,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Day_of_Week'],\n",
    "        figheight=5,\n",
    "        figwidth=15,\n",
    "        hspace=0.5,\n",
    "        nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">MONTH TOTAL</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00041-27be10ca-1ae3-436e-a056-33569fff0ca2",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Get date data\n",
    "date_data = CLEAN_DATA['accidents']['Date']\n",
    "\n",
    "# Parse months data from it\n",
    "months = [strip_number_from_zero(elements[1]) for elements in np.char.split(date_data, sep=\"/\")]\n",
    "\n",
    "# Convert the list into array and use int as dtype\n",
    "months_arr = np.array(months).astype(int)\n",
    "\n",
    "# Create xlabels\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Plot the data\n",
    "freqBar(months_arr,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Accident months'],\n",
    "        figheight=5,\n",
    "        figwidth=15,\n",
    "        hspace=0.5,\n",
    "        nrows=1,\n",
    "        xlabels=month_names\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">MONTH SPLIT INTO DAYS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data into a dictionary\n",
    "summary_dic = dict()\n",
    "for date in date_data:\n",
    "    \n",
    "    # Parse date\n",
    "    day, month, _ = date.split('/')\n",
    "    \n",
    "    # Modify the inputs if needed\n",
    "    day, month = strip_number_from_zero(day), strip_number_from_zero(month)\n",
    "    \n",
    "    # Convert month number to month name\n",
    "    month_name = month_names[int(month)-1]\n",
    "    \n",
    "    # Save it to a dictionary\n",
    "    if month_name in summary_dic:\n",
    "        summary_dic[month_name].append(int(day))\n",
    "    else:\n",
    "        summary_dic[month_name] = [int(day)]\n",
    "\n",
    "# Plot the data\n",
    "histograms(summary_dic,\n",
    "           selected_column_names=[key for key in summary_dic],\n",
    "           figheight=15,\n",
    "           figwidth=17,\n",
    "           hspace=0.9,\n",
    "           nrows=4,\n",
    "           nbins=15,\n",
    "           xticks=[i for i in range(1, 31, 2)],\n",
    "           range=(1, 31)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">Casualty Types, Road Types and Severity</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">FREQUENCY OF ACCIDENTS BY SEVERITY</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqBar(CLEAN_DATA['casualties']['Casualty_Severity'],\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Casualty_Severity'],\n",
    "        figheight=5,\n",
    "        figwidth=25,\n",
    "        nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sev = {\n",
    "    1: 'Fatal',\n",
    "    2: 'Serious',\n",
    "    3: 'Slight'\n",
    "}\n",
    "for sev, sev_name in map_sev.items():\n",
    "    mask_cas_severity = CLEAN_DATA['casualties']['Casualty_Severity'] == sev\n",
    "    number_of_impacted = CLEAN_DATA['casualties']['Casualty_Severity'][mask_cas_severity].shape[0]\n",
    "    print(f'There were {number_of_impacted} {sev_name} casualties in Manchester in 2019.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">FREQUENCY OF ACCIDENTS BY CASUALTY TYPE</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casualty_type_data = CLEAN_DATA['casualties']['Casualty_Type']\n",
    "\n",
    "freqBar(casualty_type_data,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Casualty_Type'],\n",
    "        figheight=4,\n",
    "        figwidth=15,\n",
    "        nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">CLOSER LOOK AT SELECTED CASULTY TYPES</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dictionary for casuality data\n",
    "summary_casuality = dict()\n",
    "\n",
    "# Add casualties selected by severity and filtered by major casualty types\n",
    "column_names = ['Fatal severity', 'Serious severity', 'Slight severity']\n",
    "for severity_name, severity in zip(column_names, [1, 2, 3]):\n",
    "    \n",
    "    # Select casualties with the given severity\n",
    "    severity_mask = CLEAN_DATA['casualties']['Casualty_Severity'] == severity\n",
    "    \n",
    "    # Select only certain Casualty types\n",
    "    casuality_type_mask = np.isin(CLEAN_DATA['casualties']['Casualty_Type'], np.array([0, 1, 9]))\n",
    "    \n",
    "    # Select given records using the mask\n",
    "    selected_casualties = CLEAN_DATA['casualties'][(severity_mask) & (casuality_type_mask)]\n",
    "    \n",
    "    # Add these data to summary dictionary\n",
    "    summary_casuality[severity_name] = selected_casualties['Casualty_Type']\n",
    "\n",
    "freqBar(summary_casuality,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=column_names,\n",
    "        figheight=4,\n",
    "        figwidth=15,\n",
    "        nrows=1,\n",
    "        xlabels=['Pedestrian', 'Cyclist', 'Car occupant']\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ROAD TYPES</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_cas_severity = CLEAN_DATA['casualties']['Casualty_Severity'] == 3\n",
    "selected_cas_accident_ids = CLEAN_DATA['casualties']['Accident_Index'][mask_cas_severity]\n",
    "mask_relevant_accidents = np.isin(CLEAN_DATA['accidents']['Accident_Index'], selected_cas_accident_ids)\n",
    "road_types = CLEAN_DATA['accidents']['Road_Type'][mask_relevant_accidents]\n",
    "\n",
    "freqBar(road_types,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Road_Type'],\n",
    "        figheight=4,\n",
    "        figwidth=15,\n",
    "        nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#22198A\">Task 2: Associations</h2>\n",
    "<h3 style=\"color:green\">Junction detail versus Casualty severity</h3>\n",
    "<ul>\n",
    "<li>$H_0$ (null hypothesis): There is no statistically significant relationship between junction detail and casualty severity.</li>\n",
    "<li>$H_\\alpha$ (alternative hypothesis): There is statistically significant relationship between junction detail and casualty severity.</li>\n",
    "</ul>\n",
    "<p>If the p-value $< \\alpha$, then the null hypothesis will be rejected.</p>\n",
    "<h4 style=\"color:#ff9900\">PREPARE THE TEST DATA</h4>\n",
    "<ul>\n",
    "<li><b>NOTE:</b> We had to adjust junction detail records since in crosstable we got many zeroes, therefore we decided to narrow the junction detail into the following categories: <b>Crossroads, Not at junction or within 20 metres, T or stagerred junction</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "junction_detail = CLEAN_DATA['accidents'][\"Junction_Detail\"]\n",
    "accidents_index = CLEAN_DATA['accidents'][\"Accident_Index\"]\n",
    "casualty_severity = CLEAN_DATA['casualties'][\"Casualty_Severity\"]\n",
    "casualty_acc_index = CLEAN_DATA['casualties'][\"Accident_Index\"]\n",
    "\n",
    "# Narrow down the categories\n",
    "# Accidents table\n",
    "selected_junction_categories = [0,3, 6]\n",
    "selected_cat_junction_mask = np.isin(junction_detail,\n",
    "                                     np.array(selected_junction_categories))\n",
    "junction_detail = junction_detail[selected_cat_junction_mask]\n",
    "accidents_index = accidents_index[selected_cat_junction_mask]\n",
    "# Casualties table\n",
    "acc_mask = np.isin(casualty_acc_index, accidents_index)\n",
    "casualty_severity = casualty_severity[acc_mask]\n",
    "casualty_acc_index = casualty_acc_index[acc_mask]\n",
    "\n",
    "# Since there is more casualties than accidents,\n",
    "# we need to edit junction detail column so its number of rows corresponds\n",
    "# to number of rows in casualty severity\n",
    "new_junction_detail = np.array([junction_detail[accidents_index == cas_index].data[0]\n",
    "                                for cas_index in casualty_acc_index])\n",
    "\n",
    "# Map column values representing codes to its correspnding\n",
    "# names using the provided lookup table\n",
    "junction_detail_named = map_num_cat_to_named_cat(VAR_LOOKUP,\n",
    "                                                 new_junction_detail,\n",
    "                                                 'Junction_Detail')\n",
    "\n",
    "casualty_severity_named = map_num_cat_to_named_cat(VAR_LOOKUP,\n",
    "                                                   casualty_severity,\n",
    "                                                   'Casualty_Severity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">CONDUCT THE PEARSON CHI-SQUARE TEST</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pd, expected_pd, chiVal, pVal, df = do_pearson_chi_square_test(\n",
    "    junction_detail_named,\n",
    "    casualty_severity_named,\n",
    "    ['Junction detail'],\n",
    "    ['Casualty Severity']\n",
    ")\n",
    "chiVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pValue is {round(pVal, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">COMPUTE CRAMER'S V</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramers_v = get_cramers_v(chiVal, observed_pd)\n",
    "print(f'Cramers V is {round(cramers_v, 2)} which means a weak relationship.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">PREPARE THE DATA FOR VISUAL REPORT</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get category names for both categorical variables\n",
    "# Casualty Severity\n",
    "df_severity = VAR_LOOKUP['Casualty Severity']\n",
    "cats_severity = np.unique(casualty_severity)\n",
    "cats_severity_named = get_relevant_lookup_values(df_severity, cats_severity)\n",
    "# Junction detail\n",
    "df_junction = VAR_LOOKUP['Junction Detail']\n",
    "cats_junction = [6,0, 3]\n",
    "cats_junction_named =  get_relevant_lookup_values(df_junction, cats_junction)\n",
    "# Define x ticks\n",
    "xticks = [i for i in range(1, len(cats_junction)+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">MAKE A VISUAL REPORT</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axes object\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 6))\n",
    "\n",
    "# Setup spaces horizontally and vertically\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None,\n",
    "                        top=None, wspace=0.2, hspace=0.3)\n",
    "\n",
    "# Iterate over the first row\n",
    "row1 = axs[0]\n",
    "index = 0\n",
    "for ax in row1:\n",
    "    \n",
    "    # Plot the values\n",
    "    ax.plot(xticks, list(observed_pd.iloc[:, index]), 'ro-', label='Observed')\n",
    "    ax.plot(xticks, list(expected_pd.iloc[:, index]), 'bo-', label='Expected')\n",
    "    \n",
    "    # Plot the legend within the first plot\n",
    "    if index == 0: \n",
    "        ax.set_ylabel('Casualties')\n",
    "        ax.legend(loc='best');\n",
    "        \n",
    "    # Name the axes, set the title\n",
    "    ax.set_title(f\"{cats_severity_named[index]}\\n\", fontweight=\"bold\", fontsize=14)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(cats_junction_named)\n",
    "    fig.autofmt_xdate(rotation=20)\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "row2 = axs[1]\n",
    "index = 0\n",
    "for ax in row2:\n",
    "    \n",
    "    # Plot the values\n",
    "    ax.plot(xticks, observed_pd.iloc[:, index]/expected_pd.iloc[:, index], 'go-')\n",
    "    ax.plot(xticks, [1 for _ in range(len(xticks))], 'k:')\n",
    "    \n",
    "    # Name the axes, set the title\n",
    "    if index == 0: \n",
    "        ax.set_ylabel('Observed/Expected')\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(cats_junction_named)\n",
    "    fig.autofmt_xdate(rotation=20)\n",
    "    \n",
    "    index += 1\n",
    "# fig.savefig('task_2.png', dpi=300, facecolor='w', edgecolor='w',\n",
    "#                     orientation='portrait')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#22198A\">Task 3: Map visualization</h2>\n",
    "<h3 style=\"color:green\">Casualty visualiazation on map</h3>\n",
    "<h4 style=\"color:#ff9900\">GET RELEVANT DATA</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_data = {\n",
    "    'Casualty_Severity': CLEAN_DATA['casualties']['Casualty_Severity'],\n",
    "    'Latitude': [],\n",
    "    'Longitude': []\n",
    "}\n",
    "\n",
    "for accident_index_casualty in CLEAN_DATA['casualties']['Accident_Index']:\n",
    "    \n",
    "    # Get longitude and latitude from the accident table\n",
    "    index_mask = np.isin(CLEAN_DATA['accidents']['Accident_Index'], accident_index_casualty)\n",
    "    relevant_data['Longitude'].append(CLEAN_DATA['accidents'][index_mask]['Longitude'].data[0])\n",
    "    relevant_data['Latitude'].append(CLEAN_DATA['accidents'][index_mask]['Latitude'].data[0])\n",
    "\n",
    "vals = [(cas, lat, lon) for cas, lat, lon\n",
    "        in zip(relevant_data['Casualty_Severity'],\n",
    "               relevant_data['Latitude'],\n",
    "               relevant_data['Longitude'])]\n",
    "\n",
    "relevant_data = np.array(vals,\n",
    "                         dtype=[('Casualty_Severity', int),\n",
    "                                ('Latitude', float),\n",
    "                                ('Longitude', float)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">PLOT IT WITH GIVEN SETTINGS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color map\n",
    "color_map = {\n",
    "    1: 'red',\n",
    "    2: 'orange',\n",
    "    3: 'blue'\n",
    "}\n",
    "\n",
    "# Get folium map\n",
    "M = create_folium_map(relevant_data, color_map=color_map, column_to_highlight='Casualty_Severity')\n",
    "\n",
    "# Add legend\n",
    "color_map_named = {\n",
    "    'Fatal': 'red',\n",
    "    'Serious': 'orange',\n",
    "    'Slight': 'blue'\n",
    "}\n",
    "add_legend(M, color_map_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#22198A\">Task 4: Open question</h2>\n",
    "<p><b>What are the hotspots for accidents over several years and how can better safety can be assured at these places?</b></p>\n",
    "<h3 style=\"color:green\">Load data needed for task 4</h3>\n",
    "<p><b>Note1:</b> Might take a bit longer since you are loading a big amount of data.</p>\n",
    "<p><b>Note2:</b> Accident data from other years are loaded exactly same way as accident data from year 2019, therefore we do no provide any further clarification on the way we clean them or process since this was done in previous section.</p>\n",
    "<p><b>Note3:</b> Data were obtained at this <a href=\"https://data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-safety-data\">official website</a>, which should be identical to the source of data for year 2019.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'dftRoadSafetyData_Accidents_'\n",
    "YEARS = ['2015', '2016', '2017', '2018']\n",
    "OTHER_YEARS_ACCIDENTS = {\n",
    "    year: get_accident_data_from_given_year(f\"{PATH_DATA['external']}{FILENAME}{year}.csv\")\n",
    "    for year in YEARS\n",
    "}\n",
    "ALL_YEARS_ACCIDENTS = {\n",
    "    year: get_accident_data_from_given_year(f\"{PATH_DATA['external']}{FILENAME}{year}.csv\")\n",
    "    for year in YEARS\n",
    "}\n",
    "ALL_YEARS_ACCIDENTS['2019'] = CLEAN_DATA['accidents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">Summary of accidents in Manchester from 2015 - 2019</h3>\n",
    "<p>This section briefly summarizes the accidents statistics in Manchester from 2015 - 2019.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">NUMBER OF ACCIDENTS PER YEAR</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dictionary which will hold the values\n",
    "summary_dict = dict()\n",
    "summary_dict['Year of Accident'] = [data.shape[0] for year, data in OTHER_YEARS_ACCIDENTS.items()]\n",
    "summary_dict['Year of Accident'].append(CLEAN_DATA['accidents'].shape[0])\n",
    "\n",
    "# Plot the data\n",
    "freqBar(summary_dict,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Year of Accident'],\n",
    "        figheight=4,\n",
    "        figwidth=15,\n",
    "        hspace=0.5,\n",
    "        nrows=1,\n",
    "        xlabels=list(OTHER_YEARS_ACCIDENTS.keys())+ ['2019'],\n",
    "        use_spec_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ACCIDENT SEVERITY OVER THE YEARS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dictionary containing a year and number of accidents by severity\n",
    "summary_dict = dict()\n",
    "\n",
    "# Fatal\n",
    "summary_dict['Fatal Accidents'] = [data[data['Accident_Severity'] == 1].shape[0] for year, data in OTHER_YEARS_ACCIDENTS.items()]\n",
    "summary_dict['Fatal Accidents'].append(CLEAN_DATA['accidents'][CLEAN_DATA['accidents']['Accident_Severity'] == 1].shape[0])\n",
    "\n",
    "# Serious\n",
    "summary_dict['Serious Accidents'] = [data[data['Accident_Severity'] == 2].shape[0] for year, data in OTHER_YEARS_ACCIDENTS.items()]\n",
    "summary_dict['Serious Accidents'].append(CLEAN_DATA['accidents'][CLEAN_DATA['accidents']['Accident_Severity'] == 2].shape[0])\n",
    "\n",
    "# Slight\n",
    "summary_dict['Slight Accidents'] = [data[data['Accident_Severity'] == 3].shape[0] for year, data in OTHER_YEARS_ACCIDENTS.items()]\n",
    "summary_dict['Slight Accidents'].append(CLEAN_DATA['accidents'][CLEAN_DATA['accidents']['Accident_Severity'] == 3].shape[0])\n",
    "\n",
    "# Plot the data\n",
    "freqBar(summary_dict,\n",
    "        VAR_LOOKUP,\n",
    "        selected_column_names=['Fatal Accidents', 'Serious Accidents', 'Slight Accidents'],\n",
    "        figheight=4,\n",
    "        figwidth=15,\n",
    "        hspace=0.5,\n",
    "        nrows=1,\n",
    "        xlabels=list(OTHER_YEARS_ACCIDENTS.keys())+ ['2019'],\n",
    "        use_spec_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">Hotsposts of accidents in Manchester - overview per year</h3>\n",
    "<p>The goal of this section is to explore hotspots of accidents from previous years. Next section will then combine the clusters from different years and put them on the map to see the overall trends.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">HYPER PARAMETER SETTINGS</h4>\n",
    "<ul>\n",
    "<li><b>MAX DISTANCE: </b>Maximum distance between two points on the map. For more detail, see the doc string of the function.</li>\n",
    "<li><b>MIN CLUSTER SIZE: </b>Minimum number of records to for a cluster to be considered.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 75\n",
    "MIN_CLUSTER_SIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ACCIDENT CLUSTERS IN 2019</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2019, meta_2019 = create_folium_map_clusters(CLEAN_DATA['accidents'],\n",
    "                                               max_distance=MAX_DISTANCE,\n",
    "                                               min_cluster_size=MIN_CLUSTER_SIZE,\n",
    "                                               radius = 10)\n",
    "M_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ACCIDENT CLUSTERS IN 2018</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2018, meta_2018 = create_folium_map_clusters(OTHER_YEARS_ACCIDENTS['2018'],\n",
    "                                               max_distance=MAX_DISTANCE,\n",
    "                                               min_cluster_size=MIN_CLUSTER_SIZE,\n",
    "                                               radius = 10)\n",
    "M_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ACCIDENT CLUSTERS IN 2017</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack around getting 2017 work ––> for some reason latitude and longitude data\n",
    "# were loaded as strings and not as floats as in other instances which caused fill value to be\n",
    "# unacceptable when converting strings to floats. The problem got solved by explicitly changing the fill value.\n",
    "# NOTE: Since there were not any missing values, it should not any how affect the functionality.\n",
    "OTHER_YEARS_ACCIDENTS['2017']['Latitude'].fill_value = 10**9\n",
    "OTHER_YEARS_ACCIDENTS['2017']['Longitude'].fill_value = 10**9\n",
    "M_2017, meta_2017 = create_folium_map_clusters(OTHER_YEARS_ACCIDENTS['2017'],\n",
    "                                               max_distance=MAX_DISTANCE,\n",
    "                                               min_cluster_size=MIN_CLUSTER_SIZE,\n",
    "                                               radius = 10)\n",
    "M_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ACCIDENT CLUSTERS IN 2016</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2016, meta_2016 = create_folium_map_clusters(OTHER_YEARS_ACCIDENTS['2016'],\n",
    "                                               max_distance=MAX_DISTANCE, \n",
    "                                               min_cluster_size=MIN_CLUSTER_SIZE,\n",
    "                                               radius = 10)\n",
    "M_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ACCIDENT CLUSTERS IN 2015</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2015, meta_2015 = create_folium_map_clusters(OTHER_YEARS_ACCIDENTS['2015'],\n",
    "                                    max_distance=MAX_DISTANCE,\n",
    "                                    min_cluster_size=MIN_CLUSTER_SIZE,\n",
    "                                    radius = 10)\n",
    "M_2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">Overview of accidents hotspots from past 5 years</h3>\n",
    "<p>By looking at single years, it is hard to spot a trend, therefore we decided to compute centroids of clusters for each year. These centroids are then going to be plotted on one map disnguished by color representing the given year.</p>\n",
    "<h4 style=\"color:#ff9900\">GET RELEVANT DATA</h4>\n",
    "<ul><li><b>META INFORMATION:</b> This information includes latitude, longitude and cluster label of the given point.</li>\n",
    "<li><b>SELECTION OF DATA:</b> We take meta data for each year and for each cluster within the year, we select one centroid, therefore variable relevant data includes all 5 years and corresponding centroids for the given year.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, merge all information into one dictionary first\n",
    "meta_information = {'2019': meta_2019,\n",
    "                    '2018': meta_2018,\n",
    "                    '2017': meta_2017,\n",
    "                    '2016': meta_2016,\n",
    "                    '2015': meta_2015\n",
    "                   }\n",
    "\n",
    "five_years_summary = {\n",
    "    year: map_points_to_cluster_centers(meta_info_year)\n",
    "    for year, meta_info_year in meta_information.items()\n",
    "}\n",
    "\n",
    "# Parse the data into a list\n",
    "years = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "for year, info in five_years_summary.items():\n",
    "    for lat, lon in info.values():\n",
    "        years.append(year)\n",
    "        latitude.append(lat)\n",
    "        longitude.append(lon)\n",
    "\n",
    "# Second, create a structured numpy array with following structure\n",
    "# - Year\n",
    "# - Latitude\n",
    "# - Longitude\n",
    "vals = [(year, lat, lon) for year, lat, lon\n",
    "        in zip(years,\n",
    "               latitude,\n",
    "               longitude)]\n",
    "\n",
    "relevant_data = np.array(vals,\n",
    "                         dtype=[('Year', int),\n",
    "                                ('Latitude', float),\n",
    "                                ('Longitude', float)])\n",
    "relevant_data = np.ma.asarray(relevant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">ALL CENTROIDS PLOTTED ON ONE MAP</h4>\n",
    "<ul>\n",
    "<li><b>NOTE:</b> At this step, we take all centroids for the given year and plot them onto the map. Thus, the map below represents hotspots of accidents for the past 5 years in Manchester.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "        2019: '#170536',\n",
    "        2018: '#e38c56',\n",
    "        2017: '#ff0a0a',\n",
    "        2016: '#039491',\n",
    "        2015: '#940322',\n",
    "}\n",
    "M_All = create_folium_map(relevant_data, color_map=color_map, column_to_highlight='Year', radius=7.5)\n",
    "add_legend(M_All, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">CLUSTERS FROM CENTROIDS</h4>\n",
    "<ul>\n",
    "<li><b>NOTE:</b> Previous map shows a nice overview of hotspots, but are there any patterns over the years that keep repeating? We try to answer this question by clustering hotspots from all years.</li>\n",
    "<li><b>NUMBER_OF_YEARS_PATTERN:</b> This is a very important hyper parameter, whose range for this case is from 2 to 5. The more longterm pattern you want to see, the greater this parameter must be indeed.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster all the points from previous map\n",
    "NUMBER_OF_YEARS_PATTERN = 4  # Set this parameter to see a pattern over the specified period of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, meta_ALL = create_folium_map_clusters(relevant_data,\n",
    "                                         max_distance=MAX_DISTANCE,\n",
    "                                         min_cluster_size=NUMBER_OF_YEARS_PATTERN,\n",
    "                                         radius=10)\n",
    "\n",
    "# Map the clusters to the corresponding year: from meta_all you know the location which can be\n",
    "# then used as a mask to find the year in relevant data array\n",
    "location_year_centroids = map_location_to_year(meta_ALL, relevant_data)\n",
    "color_map = {\n",
    "        2019: '#170536',\n",
    "        2018: '#f06800',\n",
    "        2017: '#ff0a0a',\n",
    "        2016: '#039491',\n",
    "        2015: '#940322',\n",
    "}\n",
    "M_All_clustered = create_folium_map(location_year_centroids,\n",
    "                          color_map=color_map,\n",
    "                          column_to_highlight='Year',\n",
    "                          radius=10)\n",
    "add_legend(M_All_clustered, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green\">Summarize the identified clusters</h3>\n",
    "<p>This section tries to summarize selected hotspots.</p>\n",
    "<h4 style=\"color:#ff9900\">PUT TOGETHER A SUMMARY OF SELECTED HOTSPOTS</h4>\n",
    "<ul>\n",
    "<li><b>NOTE:</b> We first create a dictionary where keys are simply the clusters labels, and value is another dictionary which holds a year as key and values then represent detailed information about the accident from the given year. In other words, for each hotspot a summary is created and stored within variable hotspots_accidents_summary.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspots_accidents_summary = dict()\n",
    "for row in location_year_centroids:\n",
    "    \n",
    "    # Get year\n",
    "    year = str(row['Year'])\n",
    "    \n",
    "    # Get relavant accidents based on the location from the centroid\n",
    "    relevant_accidents = map_centroid_to_locations(row[['Latitude', 'Longitude']],\n",
    "                             year,\n",
    "                             ALL_YEARS_ACCIDENTS,\n",
    "                             max_perimeter=MAX_DISTANCE)\n",
    "    \n",
    "    cluster_label = row['Label']\n",
    "    if cluster_label in hotspots_accidents_summary:\n",
    "        hotspots_accidents_summary[cluster_label][year] = relevant_accidents\n",
    "    else:\n",
    "        hotspots_accidents_summary[cluster_label] = {year: relevant_accidents}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">TOTAL NUMBER OF ACCIDENTS PER CLUSTER</h4>\n",
    "<ul>\n",
    "<li><b>NOTE:</b> Our goal here is to identify where the biggest impact can be made by summing number of accidents related to each cluster.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n_acc_cluster = dict()\n",
    "\n",
    "for cluster_id, cluster_info in hotspots_accidents_summary.items():\n",
    "    total = 0\n",
    "    for year, accidents in cluster_info.items():\n",
    "        total += accidents.shape[0]\n",
    "    total_n_acc_cluster[cluster_id] = total\n",
    "        \n",
    "sorted_dic = {k: v for k, v in sorted(total_n_acc_cluster.items(), key=lambda item: item[1])}\n",
    "top_n = list(sorted_dic.keys())[-3:]\n",
    "print(f\"The largest number of accidents happened at these clusters: {top_n}\")\n",
    "print(sorted_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#ff9900\">IDENTIFY THE TOP CLUSTERS ON THE MAP</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARD CODED DATA\n",
    "map_view_dic = {\n",
    "    6: 'https://www.google.com/maps/@53.4564752,-2.1997858,3a,75y,312.56h,84.6t/data=!3m7!1e1!3m5!1ssvkH8khlpyWpLfzgne_MAg!2e0!6s%2F%2Fgeo0.ggpht.com%2Fcbk%3Fpanoid%3DsvkH8khlpyWpLfzgne_MAg%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D345.15714%26pitch%3D0%26thumbfov%3D100!7i16384!8i8192',\n",
    "    4: 'https://www.google.com/maps/@53.4562744,-2.2257357,3a,75y,25.15h,89.12t/data=!3m6!1e1!3m4!1s5W0MsAbTfwMruiIMDaXPVQ!2e0!7i16384!8i8192',\n",
    "    1: 'https://www.google.com/maps/@53.470424,-2.2229411,3a,75y,159.88h,89.58t/data=!3m6!1e1!3m4!1skeRSOklQINAEuHN-XKBQtw!2e0!7i16384!8i8192'\n",
    "}\n",
    "\n",
    "\n",
    "for cluster_id in top_n:\n",
    "    \n",
    "    # Get location of the given cluster\n",
    "    mask_cluster_id = meta_ALL['Cluster'] == cluster_id\n",
    "    \n",
    "    # Compute the center of the given cluster - use simply a mean\n",
    "    location = meta_ALL['Latitude'][mask_cluster_id].mean(), meta_ALL['Longitude'][mask_cluster_id].mean()\n",
    "    \n",
    "    const = 0.0005\n",
    "    # Define upper bound\n",
    "    upper = location[0] + const, location[1] + const\n",
    "    # Define lower bound\n",
    "    lower = location[0] - const, location[1] - const\n",
    "    \n",
    "    \n",
    "    folium.Rectangle(bounds=[lower, upper], popup=map_view_dic[cluster_id], color='#ffee00', fill=True, fill_color='#ffee00', fill_opacity=0.2).add_to(M_All_clustered)\n",
    "M_All_clustered"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "63d3fc52-1b57-4e2b-a0b1-4e5dda88f760",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
